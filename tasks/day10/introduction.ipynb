{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06813c53",
   "metadata": {},
   "source": [
    "# ðŸ¦œðŸ”— LangChain & Agents: Comprehensive 2-Hour Workshop\n",
    "\n",
    "Welcome! In this notebook, you'll learn the fundamentals and practical implementation of **LangChain** and **Agents** for building modern AI applications.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is LangChain?](#what-is-langchain)\n",
    "2. [Core Concepts](#core-concepts)\n",
    "    - LLMs, Chains, Tools, Memory, Agents\n",
    "3. [LangChain Setup](#langchain-setup)\n",
    "4. [Working with LLMs](#working-with-llms)\n",
    "5. [Chains in LangChain](#chains-in-langchain)\n",
    "6. [Tools: Extending LLM Capabilities](#tools-extending-llm-capabilities)\n",
    "7. [Agents: Definition & Use Cases](#agents-definition--use-cases)\n",
    "8. [Building an Agent with Tools](#building-an-agent-with-tools)\n",
    "9. [Multi-Turn Conversation with Memory](#multi-turn-conversation-with-memory)\n",
    "10. [Advanced Agent Patterns](#advanced-agent-patterns)\n",
    "11. [Summary and Q&A](#summary-and-qa)\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"what-is-langchain\"></a>\n",
    "## 1. What is LangChain?\n",
    "\n",
    "**LangChain** is a Python framework for building applications powered by language models (LLMs), allowing you to combine models, tools, and data into intelligent agents and workflows.\n",
    "\n",
    "**Key strengths:**\n",
    "- Orchestration: Combine LLMs, tools, APIs, search, and databases.\n",
    "- Modularity: Plug-and-play components.\n",
    "- Agents: Build reasoning, interactive, tool-using AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"core-concepts\"></a>\n",
    "## 2. Core Concepts\n",
    "\n",
    "| Concept    | Definition                                                                                      |\n",
    "|------------|------------------------------------------------------------------------------------------------|\n",
    "| LLM        | Large Language Model (e.g., OpenAI GPT-4) used to generate or analyze text.                   |\n",
    "| Chain      | A sequence of calls (to LLMs, APIs, tools, etc.) forming a workflow.                          |\n",
    "| Tool       | A function/API/action the agent can use (calculator, search, code exec, etc.).                |\n",
    "| Memory     | Mechanism to remember past interactions (for context, chatbots, etc.).                        |\n",
    "| Agent      | An intelligent system that chooses what actions (tools/calls) to perform to solve a task.     |\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"langchain-setup\"></a>\n",
    "## 3. LangChain Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94ef0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain langchain-openai openai tiktoken ddgs python-dotenv langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d865dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create an LLM instance (GPT-3.5 Turbo or GPT-4o)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398c8b5",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "`ChatOpenAI` is a wrapper that lets you use OpenAI's chat models in LangChain.  \n",
    "You can change `\"gpt-3.5-turbo\"` to `\"gpt-4o\"` or any supported model as desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ba9f0",
   "metadata": {},
   "source": [
    "<a id=\"chains-in-langchain\"></a>\n",
    "\n",
    "## 5. Chains in LangChain\n",
    "A Chain is a sequence of steps, typically involving an LLM and optional logic or tools.\n",
    "\n",
    "Example: Simple LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94a0832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le ciel est bleu.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Translate this sentence to French: {sentence}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "result = chain.invoke({\"sentence\": \"The sky is blue.\"})\n",
    "print(result['text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2710cf5",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- `LLMChain` executes the prompt using the LLM.\n",
    "- You can chain more steps (e.g., run a search, process output, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34349963",
   "metadata": {},
   "source": [
    "<a id=\"tools-extending-llm-capabilities\"></a>\n",
    "\n",
    "## 6. Tools: Extending LLM Capabilities\n",
    "Tools allow LLMs and agents to use functions, APIs, and utilities (like search, calculator, code execution).\n",
    "\n",
    "Example: Using a Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5a0ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaswant-singh-work/Library/Python/3.9/lib/python/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result: No good DuckDuckGo Search Result was found\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "result = search.run(\"Who won the FIFA World Cup in 2018?\")\n",
    "print(\"Search result:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe2f01",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- Tools can wrap any API or function, letting the agent access live data or computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d72e47",
   "metadata": {},
   "source": [
    "<a id=\"agents-definition--use-cases\"></a>\n",
    "\n",
    "## 7. Agents: Definition & Use Cases\n",
    "What is an Agent?\n",
    "An Agent is an AI system that can:\n",
    "\n",
    "- Accept a goal (query)\n",
    "\n",
    "- Plan actions (like \"search\", \"calculate\", \"summarize\")\n",
    "\n",
    "- Use tools or APIs as needed\n",
    "\n",
    "- Synthesize results to answer or accomplish the goal\n",
    "\n",
    "Use cases:\n",
    "\n",
    "- Conversational chatbots with tool use\n",
    "\n",
    "- Autonomous data analysis\n",
    "\n",
    "- Multi-step workflows requiring reasoning and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a71d0",
   "metadata": {},
   "source": [
    "<a id=\"building-an-agent-with-tools\"></a>\n",
    "\n",
    "## 8. Building an Agent with Tools\n",
    "Let's combine LLM + Search Tool with a Function-Calling Agent (OpenAI Functions agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f56a339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `Current President of India`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaswant-singh-work/Library/Python/3.9/lib/python/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mApr 21, 2020 Â· Nirmala Sitaraman â†’ She is the current finance minister of India . Earlier she served as the defence minister as well . Vasundhra Raje Sundhiaâ†’ She served as the Chief â€¦ Jun 11, 2022 Â· Election of Indiaâ€™s Next President | How Is The President of India Elected?| UPSC/IAS 2022 - 2023 BYJU'S IAS 1.86M subscribers 744 All of us studied this at some point in school, but how many of us actually remember how the President of the India is elected? Here is a quick video, simplifying what is a largely â€¦ Life Of President Droupadi Murmu: NDTV's super exclusive. A day in the life of President Droupadi Murmu as she goes about her tasks at Rashtrapati Bhavan. We bring you her â€¦ Droupadi Murmu has been elected as the 15th President of India. A tribal leader from Odisha, she's the second woman to hold the country's highest constitutio...\u001b[0m\u001b[32;1m\u001b[1;3mThe current President of India is Droupadi Murmu. She is the 15th President of India and a tribal leader from Odisha. Droupadi Murmu is the second woman to hold the country's highest constitutional position.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent response: The current President of India is Droupadi Murmu. She is the 15th President of India and a tribal leader from Odisha. Droupadi Murmu is the second woman to hold the country's highest constitutional position.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "\n",
    "# Define the tools the agent can use\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"duckduckgo_search\",\n",
    "        func=search.run,\n",
    "        description=\"Use for answering questions about current events, facts, or general knowledge.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize the agent (function-calling agent, best for OpenAI GPT-4o or 3.5-turbo)\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the agent!\n",
    "response = agent.run(\"Who is the current President of India? What is their background?\")\n",
    "print(\"\\nAgent response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa16b3",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- The agent receives your question.\n",
    "- It decides (autonomously) if it needs to use a tool.\n",
    "- It performs searches or calculations and combines the results into a coherent answer.\n",
    "- `verbose=True` prints the agent's reasoning and tool use in detail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08034f",
   "metadata": {},
   "source": [
    "<a id=\"multi-turn-conversation-with-memory\"></a>\n",
    "\n",
    "## 9. Multi-Turn Conversation with Memory\n",
    "Agents can maintain memory for context (like a chatbot remembering earlier questions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "993d6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Who is the current Prime Minister of the UK?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The current Prime Minister of the UK is Boris Johnson. He has been in office since July 24, 2019, after winning the Conservative Party leadership election.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Who is the current Prime Minister of the UK?\n",
      "AI: The current Prime Minister of the UK is Boris Johnson. He has been in office since July 24, 2019, after winning the Conservative Party leadership election.\n",
      "Human: What is their educational background?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Boris Johnson studied at the European School, Brussels I, Ashdown House, and Eton College. He then went on to study at Balliol College, Oxford, where he studied Classics and was elected president of the Oxford Union. After graduating, he worked as a journalist before entering politics.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Who is the current Prime Minister of the UK?\n",
      "AI: The current Prime Minister of the UK is Boris Johnson. He has been in office since July 24, 2019, after winning the Conservative Party leadership election.\n",
      "Human: What is their educational background?\n",
      "AI: Boris Johnson studied at the European School, Brussels I, Ashdown House, and Eton College. He then went on to study at Balliol College, Oxford, where he studied Classics and was elected president of the Oxford Union. After graduating, he worked as a journalist before entering politics.\n",
      "Human: How old are they?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Boris Johnson was born on June 19, 1964, so he is currently 57 years old.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Who is the current Prime Minister of the UK?\n",
      "AI: The current Prime Minister of the UK is Boris Johnson. He has been in office since July 24, 2019, after winning the Conservative Party leadership election.\n",
      "Human: What is their educational background?\n",
      "AI: Boris Johnson studied at the European School, Brussels I, Ashdown House, and Eton College. He then went on to study at Balliol College, Oxford, where he studied Classics and was elected president of the Oxford Union. After graduating, he worked as a journalist before entering politics.\n",
      "Human: How old are they?\n",
      "AI: Boris Johnson was born on June 19, 1964, so he is currently 57 years old.\n",
      "Human: What political party do they belong to?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Boris Johnson is a member of the Conservative Party.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 6. Try multi-turn conversation\n",
    "print(conversation.run(\"Who is the current Prime Minister of the UK?\"))\n",
    "print(conversation.run(\"What is their educational background?\"))\n",
    "print(conversation.run(\"How old are they?\"))\n",
    "print(conversation.run(\"What political party do they belong to?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d0348c",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- Memory enables multi-turn conversations where follow-up questions reference earlier answers.\n",
    "- The agent keeps a buffer of the conversation and provides context to the LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690a513",
   "metadata": {},
   "source": [
    "<a id=\"advanced-agent-patterns\"></a>\n",
    "\n",
    "## 10. Advanced Agent Patterns\n",
    "Example: Multiple Tools (Search + Calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc6609a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `CEO of Tesla`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaswant-singh-work/Library/Python/3.9/lib/python/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mMusk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. Elon Musk co-founded and leads Tesla, SpaceX, Neuralink and The Boring Company. As the co-founder and CEO of Tesla, Elon leads all product design, engineering and global manufacturing of â€¦ Nov 20, 2023 Â· One top Musk lieutenant is Omead Afshar, a former ski instructor who has worked for Tesla for more than six years and lists his most recent position as Office of the CEO. Afshar â€¦ Elon is Technoking of Tesla and has served as our Chief Executive Officer since October 2008 and as a member of the Board since April 2004. Tesla's Chief Executive Officer, Director is Elon Musk. Other executives include Vaibhav Taneja, Chief Financial Officer; Andrew Baglino, Senior Vice President, Powertrain and Energy â€¦\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Calculator` with `124 * 15`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m1860\u001b[0m\u001b[32;1m\u001b[1;3mThe CEO of Tesla is Elon Musk. \n",
      "\n",
      "Also, 124 * 15 is equal to 1860.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The CEO of Tesla is Elon Musk. \n",
      "\n",
      "Also, 124 * 15 is equal to 1860.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import HumanInputRun\n",
    "\n",
    "# Create a simple calculator tool\n",
    "def calculator_tool(query: str) -> str:\n",
    "    try:\n",
    "        return str(eval(query))\n",
    "    except Exception:\n",
    "        return \"Sorry, I can't calculate that.\"\n",
    "\n",
    "calc_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator_tool,\n",
    "    description=\"Useful for math calculations. Input should be a valid Python expression.\"\n",
    ")\n",
    "\n",
    "# Add both tools to the agent\n",
    "tools_multi = [tools[0], calc_tool]\n",
    "\n",
    "agent_multi = initialize_agent(\n",
    "    tools=tools_multi,\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Try a multi-tool question\n",
    "result = agent_multi.run(\"Who is the CEO of Tesla, and what is 124 * 15?\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b872c",
   "metadata": {},
   "source": [
    "**Explanation:**  \n",
    "- Agents can use more than one tool and pick which to use based on your question.\n",
    "- You can add custom APIs, DB queries, or code as tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b91679",
   "metadata": {},
   "source": [
    "## 11. Summary and Q&A\n",
    "LangChain lets you combine LLMs with tools, APIs, and memory to create powerful AI applications.\n",
    "\n",
    "Chains are sequences of calls; agents make decisions and use tools.\n",
    "\n",
    "Tools can be search, code, database, or anything you define.\n",
    "\n",
    "Memory allows context-aware conversations.\n",
    "\n",
    "You now have a foundation to build interactive, tool-using AI agents in Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10504f51",
   "metadata": {},
   "source": [
    "ðŸš€ Ideas for Further Exploration\n",
    "Add a Retrieval tool (for PDF/database Q&A)\n",
    "\n",
    "Try other agent types (ReAct, Zero-Shot)\n",
    "\n",
    "Integrate with your own APIs\n",
    "\n",
    "Deploy as a web service or chatbot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
